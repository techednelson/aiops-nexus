services:
  aiops-nexus:
    container_name: aiops-nexus
    build:
      context: .
      dockerfile: Dockerfile
    working_dir: /aiops-nexus
    environment:
      DEBUG: 1
      WEBHOOK_URL: https://hooks.slack.com/services/xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx # slack and discord are compatible at this moment
      LLM: llama3.2 # if LLM is left blank, pre-installed llama3.2 will be loaded
      ENV: development
    volumes:
      - ./app:/aiops-nexus/app
    ports:
      - "5000:5000"
      - "11434"
    restart: on-failure
  open-webui:
    container_name: open-webui
    image: ghcr.io/open-webui/open-webui:main
    environment:
      - OLLAMA_BASE_URL=http://aiops-nexus:11434
    volumes:
      - open-webui:/app/backend/data
    ports:
      - "3000:8080"
    restart: always
    depends_on:
      - aiops-nexus

volumes:
  open-webui: